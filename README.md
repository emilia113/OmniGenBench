<!-- start -->

<div align="center">
<img src="assets/omnigenbench.png" alt="OmniGenBench Logo" width="90">

<h3>OmniGenBench: A Benchmark for Omnipotent Multimodal Generation across 50+ Tasks</h3>

<a href="https://github.com/emilia113">Jiayu Wang</a><sup>1,2*</sup>&nbsp;
<a href="https://sxjyjay.github.io/">Yang Jiao</a><sup>1,2*</sup>&nbsp;
<a href="https://github.com/Yue-105">Yue Yu</a><sup>1,2</sup>&nbsp;
<a href="https://qiantianwen.github.io/">Tianwen Qian</a><sup>3</sup>&nbsp;
<br>
<a href="https://scholar.google.com/citations?user=WL5mbfEAAAAJ&hl=zh-CN">Shaoxiang Chen</a><sup>4</sup>&nbsp;
<a href="https://jingjing1.github.io/">Jingjing Chen</a><sup>1,2‚Ä†</sup>&nbsp;
<a href="https://fvl.fudan.edu.cn/">Yu-Gang Jiang</a><sup>1,2</sup>

<sup>1</sup>Shanghai Key Lab of Intell. Info. Processing, School of CS, Fudan University<br>
<sup>2</sup>Shanghai Collaborative Innovation Center on Intelligent Visual Computing<br>
<sup>3</sup>School of Computer Science and Technology, East China Normal University<br>
<sup>4</sup>Minimax  

<!-- Uncomment below to show paper and huggingface badge -->
<!-- 
[![Paper](https://img.shields.io/badge/Paper-UniToken-d32f2f.svg?logo=arXiv)](https://arxiv.org/abs/2504.04423)  
<a href="https://huggingface.co/OceanJay/UniToken-AnyRes-StageII">
  <img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face%20-models-blue" alt="HF Model">
</a> 
-->

---

## üì¢ News

- **[2025/05/27]** Our paper is released.
- **[2025/05/26]** The benchmark and evaluation code will be released soon.

---

## ‚úÖ TODO

- [ ] Release evaluation code
- [ ] Release benchmark data
- [ ] Release leaderboard
- [ ] Release example results

---

## üìñ Introduction

</div>
<div align="center">
  <img src="assets/class.png" width="85%">
</div>
With 50+ diverse sub-tasks, **OmniGenBench** serves as a novel and comprehensive benchmark for evaluating the generality, adaptability, and reasoning capabilities of state-of-the-art generative models across both perception- and cognition-oriented generation tasks.

OmniGenBench ensures task diversity and difficulty by building on MegaBench, a widely acknowledged multimodal benchmark. We reverse-engineer text queries from its tasks and apply human filtering for accuracy and challenge.

To enable precise evaluation, we design dedicated evaluation protocols for both perception- and cognition-centric tasks. Each task is assigned a tailored evaluation criterion, and our protocol aligns closely with human judgment, ensuring both accuracy and consistency in performance assessment.

---

## üõ†Ô∏è Quick Start

Evaluation data and toolkit will be available shortly.

---

## üé® Model Outputs Showcase
<div align="center">
  <img src="assets/exper.png" width="100%">
</div>
